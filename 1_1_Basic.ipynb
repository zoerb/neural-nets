{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31e5302e",
   "metadata": {},
   "source": [
    "Simple network with two input neurons connected directly to a single output neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873152b5-281d-4f49-b280-ca4c67a3b18b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6494ef74",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = expected1\n",
    "\n",
    "# Plot training inputs\n",
    "plotScatter(input, expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4e085c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights\n",
    "w = np.array([[0.69829777],\n",
    "              [0.39610727]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bef2ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate\n",
    "lr = 1e-2\n",
    "\n",
    "# Calculate the model's output given input `x`\n",
    "def forward(x):\n",
    "  return np.matmul(x, w)\n",
    "\n",
    "# Calculate the error between the actual and expected output\n",
    "def loss(out):\n",
    "  # Sum to computer overall difference across all input samples\n",
    "  return abs(out - expected).sum()\n",
    "  \n",
    "# Calculate how changes to the weights affect the loss (error)\n",
    "def backward(x, out):\n",
    "  # The derivate of the loss with respect to the weights is the derivative of\n",
    "  # the loss with respect to the output, multiplied by the derivative of the\n",
    "  # output with respect to the weights.\n",
    "  #\n",
    "  # dL/dOut = abs'(expected - out) = -np.sign(expected - out)\n",
    "  # dOut/dW = x\n",
    "  #\n",
    "  # dL/dW = dL/dOut * dOut/dW\n",
    "  return elemOuter(x, np.sign(out - expected)).sum(0)\n",
    "\n",
    "# Nudge weights in the direction that will cause the loss to decrease\n",
    "def updateWeights(dLdW):\n",
    "  global w\n",
    "  w -= lr * dLdW"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fed3ad20",
   "metadata": {},
   "source": [
    "Run the following cell multiple times to see the model adjust to match the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d397c921",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = forward(input)\n",
    "\n",
    "# Visualize output and loss\n",
    "print(\"Loss: \", loss(out))\n",
    "plot(forward(test), expected)\n",
    "\n",
    "np.column_stack([out, expected])\n",
    "\n",
    "dLdW = backward(input, out)\n",
    "updateWeights(dLdW)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
